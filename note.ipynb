{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import re\n",
    "from torch.autograd import Variable\n",
    "import nltk\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = \"[«»A-Za-z0-9!#$%&'()*+,./:;<=>?@[\\]^_`{|}~—\\\"\\-]+\"\n",
    "stopwords_ru = stopwords.words(\"russian\")\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv(r\"C:\\Users\\natal\\lab_2_python\\annotation1.csv\")\n",
    "texts = []\n",
    "for absolute_path, rating in zip(df_csv['absolute_path'], df_csv['rating']):\n",
    "    with open(absolute_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        texts.append((text, rating))\n",
    "        \n",
    "df = pd.DataFrame(texts, columns=['review', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 review  rating\n",
      "0     Архимаг ищет невесту\\nМного читала академок, р...       0\n",
      "1     Манюня\\nВсё, что нужно знать об уровне юмора э...       0\n",
      "2     Удивительный Александр и крылатые кошки\\nПочем...       0\n",
      "3     Бездушный принц\\nЗахотелось прочитать какую-ни...       0\n",
      "4     Душа осьминога. Тайны сознания удивительного с...       0\n",
      "...                                                 ...     ...\n",
      "5000  Спаси меня от холода ночи\\nЖизнь деревни Каслд...       4\n",
      "5001  Витаминка\\nКаково это быть купидоном? Это волш...       4\n",
      "5002  Цветок в мужской академии магии\\nХотела бы рас...       4\n",
      "5003  Господин Неудача\\nПосле загадочной гибели роди...       4\n",
      "5004  Кай\\n\"Прежде чем войти куда-то, убедись, что т...       4\n",
      "\n",
      "[5005 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df['rating'] = df['rating'].replace({1: 0, 2: 1, 3: 2, 4: 3, 5: 4})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(review: str):\n",
    "    review = re.sub(patterns, ' ', review)\n",
    "    tokens = nltk.word_tokenize(review.lower())\n",
    "    preprocessed_text = []\n",
    "    for token in tokens:\n",
    "        lemma = morph.parse(token)[0].normal_form\n",
    "        if lemma not in stopwords_ru:\n",
    "            preprocessed_text.append(lemma)\n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  rating\n",
      "0  [архимаг, искать, невеста, читать, академка, р...       0\n",
      "1  [манюнить, всё, нужно, знать, уровень, юмор, к...       0\n",
      "2  [удивительный, александр, крылатый, кошка, поч...       0\n",
      "3  [бездушный, принц, захотеться, прочитать, нибы...       0\n",
      "4  [душа, осьминог, тайна, сознание, удивительный...       0\n"
     ]
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(lemmatize)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_lemmatized_words(words_list):\n",
    "    return ' '.join(words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(join_lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "max_words = 10000\n",
    "vectorizer = CountVectorizer(max_features=max_words, stop_words=stopwords_ru)\n",
    "sparse_matrix = vectorizer.fit_transform(df['review']).toarray()\n",
    "print(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4004, 10000)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test_valid, y_train, y_test_valid = train_test_split(sparse_matrix, np.array(df['rating']), test_size=0.2)\n",
    "x_test, x_valid, y_test, y_valid = train_test_split(x_test_valid, y_test_valid, test_size=0.5)\n",
    "\n",
    "print(x_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(10000, 1000)\n",
    "        self.linear2 = nn.Linear(1000, 100)\n",
    "        self.linear3 = nn.Linear(100, 5) #soft max [0.1, 0.2, 0.2, 0.4, 0.1] \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters() , lr=0.01)\n",
    "criterion = nn.NLLLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = Variable(torch.from_numpy(x_train)).float()\n",
    "y_train = Variable(torch.from_numpy(y_train)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.634942, Accuracy: 817/4004 (20.40%)\n",
      "Epoch: 1, Loss: 1.609973, Accuracy: 830/4004 (20.73%)\n",
      "Epoch: 2, Loss: 1.533553, Accuracy: 1231/4004 (30.74%)\n",
      "Epoch: 3, Loss: 1.630290, Accuracy: 1075/4004 (26.85%)\n",
      "Epoch: 4, Loss: 1.411689, Accuracy: 1941/4004 (48.48%)\n",
      "Epoch: 5, Loss: 1.448523, Accuracy: 1281/4004 (31.99%)\n",
      "Epoch: 6, Loss: 1.332672, Accuracy: 2026/4004 (50.60%)\n",
      "Epoch: 7, Loss: 1.265123, Accuracy: 2297/4004 (57.37%)\n",
      "Epoch: 8, Loss: 1.221911, Accuracy: 2384/4004 (59.54%)\n",
      "Epoch: 9, Loss: 1.124300, Accuracy: 2636/4004 (65.83%)\n",
      "Epoch: 10, Loss: 1.071962, Accuracy: 2599/4004 (64.91%)\n",
      "Epoch: 11, Loss: 0.984239, Accuracy: 2793/4004 (69.76%)\n",
      "Epoch: 12, Loss: 0.901571, Accuracy: 2918/4004 (72.88%)\n",
      "Epoch: 13, Loss: 0.854655, Accuracy: 2938/4004 (73.38%)\n",
      "Epoch: 14, Loss: 0.779300, Accuracy: 3023/4004 (75.50%)\n",
      "Epoch: 15, Loss: 0.706826, Accuracy: 3088/4004 (77.12%)\n",
      "Epoch: 16, Loss: 0.657047, Accuracy: 3113/4004 (77.75%)\n",
      "Epoch: 17, Loss: 0.592401, Accuracy: 3221/4004 (80.44%)\n",
      "Epoch: 18, Loss: 0.529823, Accuracy: 3426/4004 (85.56%)\n",
      "Epoch: 19, Loss: 0.476391, Accuracy: 3575/4004 (89.29%)\n",
      "Epoch: 20, Loss: 0.416748, Accuracy: 3670/4004 (91.66%)\n",
      "Epoch: 21, Loss: 0.365922, Accuracy: 3714/4004 (92.76%)\n",
      "Epoch: 22, Loss: 0.323113, Accuracy: 3758/4004 (93.86%)\n",
      "Epoch: 23, Loss: 0.276881, Accuracy: 3807/4004 (95.08%)\n",
      "Epoch: 24, Loss: 0.238970, Accuracy: 3831/4004 (95.68%)\n",
      "Epoch: 25, Loss: 0.205547, Accuracy: 3863/4004 (96.48%)\n",
      "Epoch: 26, Loss: 0.173624, Accuracy: 3892/4004 (97.20%)\n",
      "Epoch: 27, Loss: 0.148130, Accuracy: 3913/4004 (97.73%)\n",
      "Epoch: 28, Loss: 0.125478, Accuracy: 3928/4004 (98.10%)\n",
      "Epoch: 29, Loss: 0.105158, Accuracy: 3943/4004 (98.48%)\n",
      "Epoch: 30, Loss: 0.088793, Accuracy: 3951/4004 (98.68%)\n",
      "Epoch: 31, Loss: 0.075448, Accuracy: 3960/4004 (98.90%)\n",
      "Epoch: 32, Loss: 0.063606, Accuracy: 3963/4004 (98.98%)\n",
      "Epoch: 33, Loss: 0.053470, Accuracy: 3974/4004 (99.25%)\n",
      "Epoch: 34, Loss: 0.045307, Accuracy: 3978/4004 (99.35%)\n",
      "Epoch: 35, Loss: 0.038478, Accuracy: 3983/4004 (99.48%)\n",
      "Epoch: 36, Loss: 0.032766, Accuracy: 3986/4004 (99.55%)\n",
      "Epoch: 37, Loss: 0.028078, Accuracy: 3989/4004 (99.63%)\n",
      "Epoch: 38, Loss: 0.024216, Accuracy: 3992/4004 (99.70%)\n",
      "Epoch: 39, Loss: 0.021005, Accuracy: 3992/4004 (99.70%)\n",
      "Epoch: 40, Loss: 0.018244, Accuracy: 3993/4004 (99.73%)\n",
      "Epoch: 41, Loss: 0.015872, Accuracy: 3994/4004 (99.75%)\n",
      "Epoch: 42, Loss: 0.013848, Accuracy: 3996/4004 (99.80%)\n",
      "Epoch: 43, Loss: 0.012143, Accuracy: 3998/4004 (99.85%)\n",
      "Epoch: 44, Loss: 0.010720, Accuracy: 3998/4004 (99.85%)\n",
      "Epoch: 45, Loss: 0.009539, Accuracy: 3999/4004 (99.88%)\n",
      "Epoch: 46, Loss: 0.008547, Accuracy: 3999/4004 (99.88%)\n",
      "Epoch: 47, Loss: 0.007698, Accuracy: 3999/4004 (99.88%)\n",
      "Epoch: 48, Loss: 0.006955, Accuracy: 4000/4004 (99.90%)\n",
      "Epoch: 49, Loss: 0.006317, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 50, Loss: 0.005768, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 51, Loss: 0.005288, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 52, Loss: 0.004860, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 53, Loss: 0.004490, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 54, Loss: 0.004166, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 55, Loss: 0.003878, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 56, Loss: 0.003611, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 57, Loss: 0.003363, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 58, Loss: 0.003135, Accuracy: 4001/4004 (99.93%)\n",
      "Epoch: 59, Loss: 0.002924, Accuracy: 4001/4004 (99.93%)\n"
     ]
    }
   ],
   "source": [
    "epochs = 60\n",
    "loss_values = []\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_train)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    # Оценка точности модели\n",
    "    pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "    correct = pred.eq(y_train.data.view_as(pred)).sum()\n",
    "    accuracy = 100. * correct / len(x_train)\n",
    "\n",
    "    print('Epoch: {}, Loss: {:.6f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch, loss.item(), correct, len(x_train), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = Variable(torch.from_numpy(x_test)).float()\n",
    "y_test = Variable(torch.from_numpy(y_test)).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 37.2%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_test)\n",
    "    probabilities = F.softmax(y_pred, dim=1)\n",
    "    _, predicted = torch.max(probabilities, 1)\n",
    "    correct = (predicted == y_test).sum().item()\n",
    "    accuracy = correct / len(x_test)\n",
    "    print(\"Accuracy: {}%\".format(100 * accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
